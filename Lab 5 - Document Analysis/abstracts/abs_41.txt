333.29 / III35 - Application of entropy, information gain, and decision trees for intelligent decision making and data fusion

Intelligent decision makers need to be able to evaluate the consequences of their actions or the sequence of choices they have. In many problems involving intelligent decisions, the number of possible sequences can be quite large. This poster investigates how intelligent decisions can be made through construction of a decision tree and applying concepts from information theory such as information gain, entropy, and supervised datasets. A decision tree builds classification or regression models in the form of a tree structure. It breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a tree with decision nodes and leaf nodes. A decision node has two or more branches. A leaf node represents a classification or decision. The root node is the topmost decision node in a tree. Decision trees can handle both categorical and numerical data. A decision tree is built top-down from a root node and partitions the data into subsets with similar or homogeneous values. Entropy is used to calculate the homogeneity of a dataset. If the dataset is completely homogeneous the entropy is zero, and if the dataset is uniformly divided, it has entropy of one. The information gain is based on the decrease in entropy after a dataset is split on an attribute. Constructing a decision tree is finding the attribute that returns the highest information gain or the most homogeneous branches. A decision tree is transformed to a set of rules by mapping from the root node to the leaf nodes. The rules can be applied to a new or unclassified dataset to predict which inputs will have a given outcome. This poster also examines the use of an algorithm for building decision trees called ID3 (Iterative Dichotomiser 3) by J. R. Quinlan employing a top-down, greedy search using entropy and information gain through the space of possible branches in the dataset with no backtracking. As an application, this poster examines how decision trees can be applied to fuse avionics data (aircraft range, velocity) in decision making for classification, surveillance, and early warning decisions. An application to airborne avionics for air vehicle classification for reconnaissance strategies is also given.
